{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mva0  truePU  dir   tsos_detId     tsos_pt  tsos_pt_val  tsos_eta  \\\n",
      "0      6.318764   200.0  1.0  305217556.0   39.650185    39.650185  0.329402   \n",
      "1      6.487538   200.0  1.0  306221072.0   36.018456    36.018456 -0.400440   \n",
      "2      9.632208   200.0  1.0  306282500.0    6.234634     6.234634 -0.931489   \n",
      "3      5.693322   200.0  1.0  306290708.0   16.508461    16.508461 -0.405084   \n",
      "4      6.053555   200.0  1.0  306249748.0  103.609093   103.609093 -0.328105   \n",
      "...         ...     ...  ...          ...         ...          ...       ...   \n",
      "92109  4.712126   200.0  1.0  306221076.0   24.187933    24.187933 -0.207863   \n",
      "92110  5.961148   200.0  1.0  305205272.0   24.159716    24.159716  0.044301   \n",
      "92111  6.035942   200.0  1.0  305139736.0   74.839699    74.839699  0.407732   \n",
      "92112  4.046599   200.0  1.0  306241556.0   20.078423    20.078423 -0.118347   \n",
      "92113  3.463670   200.0  1.0  305156116.0    4.497806     4.497806  0.385827   \n",
      "\n",
      "       tsos_phi  tsos_glob_x  tsos_glob_y  ...       l1z3      hitx3  \\\n",
      "0     -0.128050    10.617460    -1.383845  ...   1.385910  10.617460   \n",
      "1      1.861978    -4.168917    13.792019  ...  -5.001445  -4.168918   \n",
      "2     -1.098837     6.627633   -13.418450  ... -18.353302   6.627632   \n",
      "3     -0.647659    11.883166    -9.077248  ...  -0.665086  11.883169   \n",
      "4     -2.799292   -14.031969    -5.013668  ...  -0.786880 -14.031969   \n",
      "...         ...          ...          ...  ...        ...        ...   \n",
      "92109  1.865497    -4.230155    13.771213  ...   0.348753  -4.230155   \n",
      "92110 -1.119260     4.429160    -9.188538  ...   3.959182   4.429160   \n",
      "92111  0.231887     9.962119     2.344369  ...   4.947318   9.962119   \n",
      "92112  2.958141   -14.689391     2.661529  ...  -1.531976 -14.689391   \n",
      "92113  1.400358     1.867534    10.030945  ...   0.635742   1.867534   \n",
      "\n",
      "           hity3      hitz3     l1x4     l1y4     l1z4    hitx4    hity4  \\\n",
      "0      -1.383845   1.286480 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "1      13.792018  -4.673930 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "2     -13.418451 -18.341318 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "3      -9.077244  -0.705812 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "4      -5.013668  -0.772612 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "...          ...        ...      ...      ...      ...      ...      ...   \n",
      "92109  13.771213   0.465536 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "92110  -9.188538   3.939384 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "92111   2.344369   4.760328 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "92112   2.661529  -1.296492 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "92113  10.030945   0.538574 -99999.0 -99999.0 -99999.0 -99999.0 -99999.0   \n",
      "\n",
      "         hitz4  \n",
      "0     -99999.0  \n",
      "1     -99999.0  \n",
      "2     -99999.0  \n",
      "3     -99999.0  \n",
      "4     -99999.0  \n",
      "...        ...  \n",
      "92109 -99999.0  \n",
      "92110 -99999.0  \n",
      "92111 -99999.0  \n",
      "92112 -99999.0  \n",
      "92113 -99999.0  \n",
      "\n",
      "[92114 rows x 87 columns]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Read data, no preprocessing\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the .pkl file\n",
    "with open('../DYToLL_PU200_Spring23_NThltIter2FromL1/DYToLL_PU200_Spring23_NThltIter2FromL1_Barrel.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Extract the DataFrame and the array from the tuple\n",
    "df = data[0]  # The first element is the DataFrame\n",
    "array = data[1]  # The second element is the NumPy array\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# If you need to work with the array, you can do so separately\n",
    "print(array)\n",
    "\n",
    "# Slicing the data\n",
    "# Randomly select 300 indices from the DataFrame\n",
    "random_indices = np.random.choice(df.index, size=300, replace=False)\n",
    "\n",
    "# Select the corresponding rows from the DataFrame\n",
    "df_sampled = df.loc[random_indices]\n",
    "\n",
    "# Select the corresponding labels from the array\n",
    "array_sampled = array[random_indices]\n",
    "\n",
    "# Display the sampled DataFrame and array\n",
    "print(df_sampled)\n",
    "print(array_sampled)\n",
    "\n",
    "# Save the sampled data to an Excel file\n",
    "# df_sampled.to_excel(\"./sampled_data.xlsx\")\n",
    "\n",
    "# Convert the sampled data to tensors\n",
    "input_X = torch.tensor(df_sampled.values, dtype=torch.float32)\n",
    "label_y = torch.tensor(array_sampled, dtype=torch.float32)\n",
    "\n",
    "print(input_X)\n",
    "print(label_y)\n",
    "\n",
    "print(input_X.size())\n",
    "print(label_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   expd2hitl1tk1  expd2hitl1tk2  expd2hitl1tk3  dR_L1TkMuSeedP  \\\n",
      "0       0.990987       0.713180       0.987402        0.004175   \n",
      "1       0.689316       0.764362       0.674484        0.005500   \n",
      "2       0.548451       0.480737       0.999237        0.027850   \n",
      "3       0.767553       0.994757       0.998245        0.008985   \n",
      "4       0.741779       0.999612       0.997960        0.001913   \n",
      "\n",
      "   dPhi_L1TkMuSeedP  tsos_qbp  tsos_dydz  tsos_dxdz  tsos_err0     tsos_err2  \\\n",
      "0         -0.003510 -0.023912  -0.335638  -0.038410   0.000043  6.029049e-08   \n",
      "1          0.004065  0.025677  -0.411500   0.036356   0.000068  6.829735e-08   \n",
      "2         -0.027783 -0.109400   1.075664   0.080918   0.000016  1.170655e-07   \n",
      "3         -0.008914 -0.055924   0.417587   0.080094   0.000023  6.257859e-08   \n",
      "4          0.001653  0.009154   0.334038  -0.009316   0.000005  2.613838e-08   \n",
      "\n",
      "      tsos_err5  y_label  \n",
      "0  1.060757e-07      1.0  \n",
      "1  7.030542e-08      1.0  \n",
      "2  2.279720e-07      1.0  \n",
      "3  7.708970e-08      1.0  \n",
      "4  1.955437e-08      1.0  \n"
     ]
    }
   ],
   "source": [
    "# Read the data and preprocess it\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming your project structure as above, add the parent directory to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Now you should be able to import from BDT_model\n",
    "from BDT_model.HLTIO import preprocess\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# from BDT_model.HLTIO import preprocess\n",
    "\n",
    "# Path to the original pickle file\n",
    "pkl_path = \"../DYToLL_PU200_Spring23_NThltIter2FromL1/DYToLL_PU200_Spring23_NThltIter2FromL1_Barrel.pkl\"\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pkl_path, \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Assume the first element of the tuple is the original DataFrame\n",
    "df = data[0]\n",
    "\n",
    "# Apply setClassLabel to compute the class labels\n",
    "df = preprocess.setClassLabel(df)\n",
    "\n",
    "# Compute the distance features (expd2hitl1tk1,..,expd2hitl1tk4) \n",
    "# We use addAbsDist=False as in the readSeedTree flow to drop the d2hitl1tk variables.\n",
    "df = preprocess.addDistHitL1Tk(df, addAbsDist=False)\n",
    "\n",
    "# Define the list of required columns:\n",
    "required_columns = [\n",
    "    \"expd2hitl1tk1\",\n",
    "    \"expd2hitl1tk2\",\n",
    "    \"expd2hitl1tk3\",\n",
    "    \"dR_L1TkMuSeedP\",\n",
    "    \"dPhi_L1TkMuSeedP\",\n",
    "    \"tsos_qbp\",\n",
    "    \"tsos_dydz\",\n",
    "    \"tsos_dxdz\",\n",
    "    \"tsos_err0\",\n",
    "    \"tsos_err2\",\n",
    "    \"tsos_err5\",\n",
    "    \"y_label\"  # class label from setClassLabel\n",
    "]\n",
    "\n",
    "# Check whether all required columns are present; if not, issue a warning.\n",
    "missing = [col for col in required_columns if col not in df.columns]\n",
    "if missing:\n",
    "    print(\"Warning: The following required columns are missing:\", missing)\n",
    "\n",
    "# Create a new DataFrame with only the required columns.\n",
    "df_final = df[required_columns].copy()\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "print(df_final.head())\n",
    "\n",
    "# Optionally, save the resulting DataFrame to an Excel file.\n",
    "# df_final.to_excel(\"processed_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qml)",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
